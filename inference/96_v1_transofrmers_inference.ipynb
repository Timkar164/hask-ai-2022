{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e25d7265",
   "metadata": {},
   "source": [
    "# Классификация текста с помощью трансформера BERT\n",
    "\n",
    "Оригинальная идея подчерпнута отсюда https://www.kaggle.com/c/learn-ai-bbc и отсюда https://habr.com/ru/post/655517/\n",
    "\n",
    "\n",
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f0f0b3-93b0-4ed1-ba74-bc1bcf5664da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acb66b01-d303-4c1a-affc-69464d3ec275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vasiliev\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, BertTokenizer\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert, num_classes = 96):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "        self.fc2 = nn.Linear(512,num_classes)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "    \n",
    "    def forward(self, sent_id, mask):\n",
    "        _, cls_hs = self.bert(sent_id, attention_mask = mask, return_dict = False)\n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "class TansformerRuBERT:\n",
    "    def __init__(self, weights = 'saved_weights_2_digits.pt', dev='cpu'):\n",
    "        # dev='cuda'\n",
    "        self.device = torch.device(dev)\n",
    "        self.bert = AutoModel.from_pretrained(\"DeepPavlov/rubert-base-cased-sentence\")\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased-sentence\")\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.model = BERT_Arch(self.bert)\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.load_state_dict(torch.load(weights, map_location=torch.device(self.device)))\n",
    "        self.model.eval()\n",
    "        \n",
    "    def preprocess(self, line):\n",
    "        support_chars = {33: ' ', 34: ' ', 35: ' ', 36: ' ', 37: ' ', 38: ' ', 39: ' ', 40: ' ', 41: ' ', 42: ' ', 43: ' ', 44: ' ', 45: ' ', 46: ' ', 47: ' ', 58: ' ', 59: ' ', 60: ' ', 61: ' ', 62: ' ', 63: ' ', 64: ' ', 91: ' ', 92: ' ', 93: ' ', 94: ' ', 95: ' ', 96: ' ', 123: ' ', 124: ' ', 125: ' ', 126: ' '}\n",
    "        line = line.translate(support_chars).lower().split(' ')\n",
    "        t = [token for token in line if token not in russian_stopwords and token != \" \" and token.strip() not in punctuation]\n",
    "        return ' '.join(t)\n",
    "        \n",
    "        \n",
    "    def predict(self, line):\n",
    "        line = self.preprocess(line)\n",
    "        \n",
    "        sequence = self.tokenizer.encode(line, \n",
    "                                        max_length = 15, \n",
    "                                        padding = 'max_length',\n",
    "                                        truncation = True)\n",
    "        mask = torch.tensor([1]*len(sequence)).to(self.device)\n",
    "        sequence = torch.tensor(sequence).to(self.device)\n",
    "        mask = torch.unsqueeze(mask, 0)\n",
    "        sequence = torch.unsqueeze(sequence, 0)\n",
    "        res = self.model(sequence, mask)\n",
    "        res = int(res.argmax(dim=1).cpu().numpy())\n",
    "        if res> 77:\n",
    "            return res+2\n",
    "        else:\n",
    "            return res+1\n",
    "    \n",
    "myModel = TansformerRuBERT()\n",
    "\n",
    "\n",
    "input_line = 'изделия прочие пластмасс изделия прочих материалов товарных позиций 3901 3914 прочие прочие прочие прочие' \n",
    "res = myModel.predict(input_line)\n",
    "\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1864bbeb-4396-4cd1-a8ca-3033310ef592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
