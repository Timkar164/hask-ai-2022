{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "import re\n",
    "import psycopg2\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.base import BaseEstimator\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "  #создание вероятностного распределения\n",
    "  proba = np.exp(-x)\n",
    "  return proba / sum(proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeighborSampler(BaseEstimator):\n",
    "  def __init__(self, k=5, temperature=10.0):\n",
    "    self.k=k\n",
    "    self.temperature = temperature\n",
    "  def fit(self, X, y):\n",
    "    self.tree_ = BallTree(X)\n",
    "    self.y_ = np.array(y)\n",
    "  def predict(self, X, random_state=None):\n",
    "    distances, indices = self.tree_.query(X, return_distance=True, k=self.k)\n",
    "    result = []\n",
    "    resultDist = []\n",
    "    for distance, index in zip(distances, indices):\n",
    "      result.append(np.random.choice(index, p=softmax(distance * self.temperature)))\n",
    "      resultDist.append(np.random.choice(distance, p=softmax(distance * self.temperature)))\n",
    "    return self.y_[result] , resultDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bot(object):\n",
    "    def __init__(self):\n",
    "        self.morph = pymorphy2.MorphAnalyzer(lang='ru')\n",
    "    def getData(self):\n",
    "        with open('chatbot/answer2.json','r') as f:\n",
    "         response = json.load(f)['items']\n",
    "        self.answer = dict()\n",
    "        answer_id=[] \n",
    "        questions=[]\n",
    "        for i in response:\n",
    "               self.answer[i['id']]=i['answer']\n",
    "        with open('chatbot/question2.json','r') as f:\n",
    "          response = json.load(f)['items']\n",
    "        # посчитаем количество вопросов\n",
    "        transform=0\n",
    "\n",
    "        for row in response:\n",
    "          if row['question']>\"\":\n",
    "           if row['answerid']>0:\n",
    "            phrases=row['question']\n",
    "   \n",
    "            # разбираем вопрос на слова\n",
    "           words=phrases.split(' ')\n",
    "           phrase=\"\"\n",
    "           for word in words:\n",
    "                word = self.morph.parse(word)[0].normal_form  \n",
    "                phrase = phrase + word + \" \"\n",
    "                # Если длинна полученной фразы больше 0 добавляем ей в массив вопросов и массив кодов ответов\n",
    "           if (len(phrase)>0):\n",
    "             questions.append(phrase.strip())\n",
    "             answer_id.append(row['answerid'])\n",
    "             transform=transform+1\n",
    "        return transform , self.answer , questions , answer_id\n",
    "    def buildModel(self):\n",
    "           transform , answer , questions , answer_id = self.getData()\n",
    "           vectorizer_q = TfidfVectorizer()\n",
    "           vectorizer_q.fit(questions)\n",
    "           matrix_big_q = vectorizer_q.transform(questions)\n",
    "           if transform>200:\n",
    "              transform=200\n",
    "           svd_q = TruncatedSVD(n_components=transform)\n",
    "           svd_q.fit(matrix_big_q)\n",
    "           matrix_small_q = svd_q.transform(matrix_big_q)\n",
    "           ns_q = NeighborSampler()\n",
    "           ns_q.fit(matrix_small_q, answer_id) \n",
    "           self.pipe_q = make_pipeline(vectorizer_q, svd_q, ns_q)\n",
    "    def send(self,command):\n",
    "         words= re.split('\\W',command)\n",
    "         phrase=\"\"\n",
    "         for word in words:\n",
    "           word = self.morph.parse(word)[0].normal_form  # морфируем слово вопроса в нормальную словоформу\n",
    "           # Нормализуем словоформу каждого слова и соберем обратно фразу\n",
    "           phrase = phrase + word + \" \"\n",
    "         result = self.pipe_q.predict([phrase.strip()])\n",
    "         reply_id = int(result[0])\n",
    "         return self.answer[reply_id] , result[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = Bot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.buildModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Привет. Я бот Roboto и с радостью отвечу на ваши вопросы', 0.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.send('Привет')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
